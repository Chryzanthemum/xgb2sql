{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module name here\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def xgb2sql(xgb_booster, table_name: str, index_list=[], sql_type=None):\n",
    "    \"\"\"\n",
    "    Takes in an XGB Booster and converts it to a SQL query. \n",
    "    Look, I'm not saying you should use this, but I'm saying it now exists.\n",
    "    I imagine any sort of tree based model could be relatively easily converted to a SQL query using this.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xgb_booster: xgboost.core.Booster\n",
    "        https://xgboost.readthedocs.io/en/latest/tutorials/model.html\n",
    "    table_name: str\n",
    "        The name of the SQL table to query from. Obviously this table must be the same as the model inputs or else it won't work.\n",
    "    index_list : list\n",
    "        Anything in the list will be passed through as a column in your final output. \n",
    "    sql_type : str\n",
    "        If there's a better way native to the sql_type to generate the code, it will be used. \n",
    "        Otherwise defaults to PostgreSQL compliant code. \n",
    "    \"\"\"\n",
    "\n",
    "    def _json_parse(xgb_booster) -> str:\n",
    "\n",
    "        ret = xgb_booster.get_dump(dump_format=\"json\")\n",
    "\n",
    "        json_string = \"[\\n\"\n",
    "        for i, _ in enumerate(ret):\n",
    "            json_string = json_string + ret[i]\n",
    "            if i < len(ret) - 1:\n",
    "                json_string = json_string + \",\\n\"\n",
    "        json_string = json_string + \"\\n]\"\n",
    "\n",
    "        return json.loads(json_string)\n",
    "\n",
    "    def _psql_eval(index_list: List[str], leaf_list: List) -> str:\n",
    "\n",
    "        column_string = \"\\n\\t+ \".join(columns)\n",
    "        if len(index_list) > 0:\n",
    "            query = f\"\"\"\\nSELECT\n",
    "    {index_string},       \n",
    "    1 / ( 1 + EXP ( - (\n",
    "    {column_string}) ) ) AS score,\n",
    "    'consumer_arbiter_action_variable_score_model_V1' AS model,\n",
    "    CURRENT_TIMESTAMP() AS _created_at \n",
    "FROM booster_output\"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\\nSELECT \n",
    "    1 / ( 1 + EXP ( - ( \n",
    "    {column_string} ) ) ) AS score\n",
    "FROM booster_output\"\"\"\n",
    "\n",
    "        return query\n",
    "\n",
    "    def _bq_eval(index_list: List[str]) -> str:\n",
    "        def _string_parse(index_list: List[str]) -> str:\n",
    "\n",
    "            a = [\"'\" + i + \"'\" for i in index_list]\n",
    "            return \",\".join(a)\n",
    "\n",
    "        if len(index_list) > 0:\n",
    "            query = f\"\"\",\n",
    "\n",
    "json_collapsed AS (\n",
    "    SELECT\n",
    "        {index_string},\n",
    "        TO_JSON_STRING(booster_output) AS json_text\n",
    "    FROM booster_output\n",
    "),\n",
    "\n",
    "unnested AS (\n",
    "    SELECT\n",
    "        {index_string},\n",
    "        REGEXP_REPLACE(SUBSTR(pairs, 1, STRPOS(pairs, ':') - 1), '^\"|\"$', '') AS variable_name,\n",
    "        REGEXP_REPLACE(SUBSTR(pairs, STRPOS(pairs, ':') + 1, LENGTH(pairs)), '^\"|\"$', '') AS value\n",
    "    FROM json_collapsed, UNNEST(SPLIT(REGEXP_REPLACE(json_text, '^{{|}}$', ''), ',\"')) pairs\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    {index_string},\n",
    "    1 / ( 1 + EXP ( - SUM ( CAST ( value AS FLOAT64 ) ) ) ) AS score,\n",
    "    'consumer_arbiter_action_variable_score_model_V1' AS model,\n",
    "    CURRENT_TIMESTAMP() AS _created_at\n",
    "FROM unnested\n",
    "WHERE variable_name NOT IN (\n",
    "    {_string_parse(index_list)}\n",
    ")\n",
    "GROUP BY {index_string}\n",
    "\"\"\"\n",
    "\n",
    "        else:\n",
    "            query = f\"\"\",\n",
    "    \n",
    "json_collapsed AS (\n",
    "    SELECT\n",
    "        TO_JSON_STRING(branching) AS json_text\n",
    "    FROM booster_output\n",
    "),\n",
    "\n",
    "unnested AS (\n",
    "    SELECT\n",
    "        REGEXP_REPLACE(SUBSTR(pairs, 1, STRPOS(pairs, ':') - 1), '^\"|\"$', '') AS variable_name,\n",
    "        REGEXP_REPLACE(SUBSTR(pairs, STRPOS(pairs, ':') + 1, LENGTH(pairs)), '^\"|\"$', '') AS value\n",
    "    FROM json_collapsed, UNNEST(SPLIT(REGEXP_REPLACE(json_text, '^{{|}}$', ''), ',\"')) pairs\n",
    ")\n",
    "\n",
    "SELECT\n",
    "    1 / ( 1 + EXP ( - SUM ( CAST ( value AS FLOAT64 ) ) ) ) AS score\n",
    "FROM unnested\n",
    "\"\"\"\n",
    "        return query\n",
    "\n",
    "    def _extract_values(obj, key):\n",
    "\n",
    "        key_dict = {}\n",
    "        arr = []\n",
    "        info_dict = {}\n",
    "\n",
    "        def _extract(obj, arr, key, prev=None):\n",
    "\n",
    "            if isinstance(obj, dict):\n",
    "                try:\n",
    "                    info_dict.update(\n",
    "                        {\n",
    "                            obj[\"nodeid\"]: {\n",
    "                                \"parent\": prev,\n",
    "                                \"split_column\": obj[\"split\"],\n",
    "                                \"split_number\": obj[\"split_condition\"],\n",
    "                                \"if_less_than\": obj[\"yes\"],\n",
    "                                \"if_greater_than\": obj[\"no\"],\n",
    "                                \"if_null\": obj[\"missing\"],\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                except:\n",
    "                    info_dict.update({obj[\"nodeid\"]: {\"parent\": prev}})\n",
    "\n",
    "                prev = obj[\"nodeid\"]\n",
    "\n",
    "                for k, v in obj.items():\n",
    "                    if isinstance(v, (dict, list)):\n",
    "                        _extract(v, arr, key, prev)\n",
    "                    elif k == key:\n",
    "                        key_dict.update({obj[\"nodeid\"]: v})\n",
    "            elif isinstance(obj, list):\n",
    "                for item in obj:\n",
    "                    _extract(item, arr, key, prev)\n",
    "            return key_dict\n",
    "\n",
    "        results = _extract(obj, arr, key)\n",
    "        return results, info_dict\n",
    "\n",
    "    def _recurse_backwards(first_node) -> str:\n",
    "\n",
    "        query_list: List[str] = []\n",
    "\n",
    "        def _recurse(x) -> None:\n",
    "\n",
    "            prev_node = x\n",
    "            next_node = splits[prev_node][\"parent\"]\n",
    "            try:\n",
    "                node = splits[next_node]\n",
    "                if (node[\"if_less_than\"] == prev_node) & (\n",
    "                    node[\"if_less_than\"] == node[\"if_null\"]\n",
    "                ):\n",
    "                    text = f\"(({node['split_column']} < {node['split_number']}) OR ({node['split_column']} IS NULL))\"\n",
    "                    query_list.insert(0, text)\n",
    "                    _recurse(next_node)\n",
    "                elif node[\"if_less_than\"] == prev_node:\n",
    "                    text = f\"({node['split_column']} < {node['split_number']})\"\n",
    "                    query_list.insert(0, text)\n",
    "                    _recurse(next_node)\n",
    "                elif (node[\"if_greater_than\"] == prev_node) & (\n",
    "                    node[\"if_greater_than\"] == node[\"if_null\"]\n",
    "                ):\n",
    "                    text = f\"(({node['split_column']} >= {node['split_number']}) OR ({node['split_column']} IS NULL))\"\n",
    "                    query_list.insert(0, text)\n",
    "                    _recurse(next_node)\n",
    "                elif node[\"if_greater_than\"] == prev_node:\n",
    "                    text = f\"({node['split_column']} >= {node['split_number']})\"\n",
    "                    query_list.insert(0, text)\n",
    "                    _recurse(next_node)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        _recurse(first_node)\n",
    "\n",
    "        s = \"\\n\\t\\t\\tAND \"\n",
    "\n",
    "        return s.join(query_list)\n",
    "\n",
    "    tree_json = _json_parse(xgb_booster)\n",
    "\n",
    "    index_list = [str(i) for i in index_list]\n",
    "    index_string = \",\\n\".join(index_list)\n",
    "\n",
    "    leaf_list = []\n",
    "    columns = []\n",
    "    counter = 0\n",
    "    for i in range(0, len(tree_json)):\n",
    "        leaves, splits = _extract_values(tree_json[i], \"leaf\")\n",
    "        column_list = []\n",
    "\n",
    "        for base_leaf in leaves:\n",
    "            leaf_query = (\n",
    "                \"\\t\\t\\tWHEN \"\n",
    "                + _recurse_backwards(base_leaf)\n",
    "                + f\"\\n\\t\\tTHEN {leaves[base_leaf]}\"\n",
    "            )\n",
    "\n",
    "            column_list.append(leaf_query)\n",
    "\n",
    "        column = f\"column_{counter}\"\n",
    "        column_list = \"\\t\\tCASE\\n\" + (\"\\n\").join(column_list) + f\"\\n\\t\\tEND AS {column}\"\n",
    "\n",
    "        columns.append(column)\n",
    "        leaf_list.append(column_list)\n",
    "        counter += 1\n",
    "\n",
    "    if sql_type == \"bigquery\":\n",
    "        output = _bq_eval(index_list)\n",
    "    else:\n",
    "        output = _psql_eval(index_list, leaf_list)\n",
    "\n",
    "    query = (\n",
    "        \"WITH booster_output AS (\\n\\tSELECT\\n\"\n",
    "        + \", \\n\".join((index_list + leaf_list))\n",
    "        + f\"\\n\\tFROM {table_name}\"\n",
    "        + f\"\\n\\tWHERE source = 'test'\\n)\"\n",
    "        + f\"\\n{output}\"\n",
    "    )\n",
    "\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
