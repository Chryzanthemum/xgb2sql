{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB2SQL\n",
    "\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def clean_multiline_str(prefix_nls: int = 0, suffix_nls: int = 0, spaces: int = 0):\n",
    "    def wrap(multi_line_str_func: Callable[..., str]):\n",
    "        def inner(*args, **kwargs):\n",
    "            s = multi_line_str_func(*args, **kwargs)\n",
    "            pnls = \"\\n\" * prefix_nls\n",
    "            snls = \"\\n\" * suffix_nls\n",
    "            ses = \" \" * spaces\n",
    "            sl = [line for line in s.split(\"\\n\")]\n",
    "            min_lstrip = min(\n",
    "                [len(line) - len(line.lstrip()) for line in sl if line.strip()]\n",
    "            )\n",
    "            sl = [line[min_lstrip:] if len(\n",
    "                line) >= min_lstrip else \"\" for line in sl]\n",
    "            sl = [f\"{ses}{line}\" for line in sl]\n",
    "            s = \"\\n\".join(sl)\n",
    "            s = s.strip(\"\\n\")\n",
    "            s = f\"{pnls}{s}{snls}\"\n",
    "            return s\n",
    "        return inner\n",
    "    return wrap\n",
    "\n",
    "\n",
    "class XGBFmap:\n",
    "    '''\n",
    "    This exists because xgb is a kinda questionably coded library (with incredible math behind it). Pass through a list of integers that aren't indicators (1/0) to here or else the fmap will break.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 path: Optional[str] = None,\n",
    "                 file_txt: str = \"fmap.txt\"\n",
    "                 ) -> None:\n",
    "        if path:\n",
    "            self.PATH = Path(path) / file_txt\n",
    "        else:\n",
    "            self.PATH = Path.cwd() / file_txt\n",
    "\n",
    "    def create_fmap(self,\n",
    "                    X: pd.DataFrame,\n",
    "                    non_indicator_ints: Optional[List[str]] = None\n",
    "                    ) -> None:\n",
    "        if not non_indicator_ints:\n",
    "            non_indicator_ints = []\n",
    "\n",
    "        fmaps_df = (\n",
    "            pd.DataFrame(X.dtypes)\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": \"name\", 0: \"dtype\"})\n",
    "            .assign(\n",
    "                typ=lambda d: d.apply(\n",
    "                    lambda x:\n",
    "                    \"int\" if x[\"name\"] in non_indicator_ints\n",
    "                    else \"i\" if str(x[\"dtype\"]).startswith(\"int\")\n",
    "                    else \"q\",\n",
    "                    axis=1),\n",
    "                row=lambda d: d.index,\n",
    "            )\n",
    "            .loc[:, [\"row\", \"name\", \"typ\"]]\n",
    "        )\n",
    "\n",
    "        fmaps_df.to_csv(self.PATH, header=False, index=False, sep=\" \")\n",
    "\n",
    "    def delete_fmap(self) -> None:\n",
    "        Path.unlink(self.PATH)\n",
    "\n",
    "class XGB2SQL(object):\n",
    "    def __init__(self,\n",
    "                 xgb_model,\n",
    "                 model_type: Literal[\"Classifier\", \"Regressor\"],\n",
    "                 model_name: str = \"XGB_model\",\n",
    "                 data_source_name: str,\n",
    "                 index_columns: Optional[List[str]] = None,\n",
    "                 fmap_path: Optional[str] = None,\n",
    "                 fmap_file_txt: str = \"fmap.txt\",\n",
    "                 output_path: Optional[str] = None,\n",
    "                 output_filename: str = \"model.sql\"\n",
    "                 ) -> None:\n",
    "    \"\"\"\n",
    "    Takes in an XGB model and converts it to a SQL query. \n",
    "    Look, I'm not saying you should use this, but I'm saying it now exists. An example use case would be training your data on a small sample set, running this on the results of that model, and then leveraging Redshift/BigQuery to cheaply and quickly generate billions of predictions.\n",
    "    I imagine any sort of tree based model could be relatively easily converted to a SQL query using this.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xgb_model: xgboost\n",
    "        https://xgboost.readthedocs.io/en/latest/tutorials/model.html\n",
    "    model_type:\n",
    "        The way branches are converted into predictions is different for the two types of models but the concept is the same\n",
    "    model_name:\n",
    "        Useful for versioning.\n",
    "    data_source_name:\n",
    "        The name of the SQL table to query from. Obviously this table must have the same columns as the model inputs or else it won't work.\n",
    "    index_columns:\n",
    "        Anything in the list will be passed through as a column in your final output. \n",
    "    \"\"\"\n",
    "\n",
    "        self.xgb_base_score = xgb_model.base_score\n",
    "        self.xgb_booster = xgb_model.get_booster()\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.model_name = model_name\n",
    "\n",
    "        self.data_source_name = data_source_name\n",
    "        if index_columns:\n",
    "            self.index_columns = index_columns\n",
    "        else:\n",
    "            self.index_columns = []\n",
    "        self.index_string = \", \".join(self.index_columns)\n",
    "\n",
    "        if fmap_path:\n",
    "            self.FMAP_PATH = Path(fmap_path) / fmap_file_txt\n",
    "        else:\n",
    "            self.FMAP_PATH = Path.cwd() / fmap_file_txt\n",
    "\n",
    "        if output_path:\n",
    "            self.OUTPUT_PATH = Path(output_path) / output_filename\n",
    "        else:\n",
    "            self.OUTPUT_PATH = Path.cwd() / output_filename\n",
    "\n",
    "    def _json_parse(self) -> str:\n",
    "        # fmap must be read in from a file path\n",
    "        ret = self.xgb_booster.get_dump(\n",
    "            dump_format=\"json\", fmap=self.FMAP_PATH.as_posix()\n",
    "        )\n",
    "        clean_string = \", \".join(ret).replace(\"\\n\", \"\")\n",
    "        json_string = f\"[{clean_string}]\"\n",
    "\n",
    "        return json.loads(json_string)\n",
    "\n",
    "    @clean_multiline_str(prefix_nls=2, suffix_nls=1)\n",
    "    def _sql_eval(self,\n",
    "                  columns: List[str]\n",
    "                  ) -> str:\n",
    "        column_string = \" + \".join(columns)\n",
    "\n",
    "        if self.model_type == \"Classifier\":\n",
    "            # Note: xgboost doesn't use base_score for predict_proba(X)[:,1]\n",
    "            score_string = (\n",
    "                f\"1 / ( 1 + `EXP` ( - ({column_string}) ) )\"\n",
    "            )\n",
    "        else:\n",
    "            score_string = f\"{column_string} + {self.xgb_base_score}\"\n",
    "\n",
    "        if self.index_columns:\n",
    "            query = f\"\"\"\n",
    "                SELECT\n",
    "                  {self.index_string},\n",
    "                  {score_string} AS score,\n",
    "                  '{self.model_name}' AS model_name,\n",
    "                  CURRENT_TIMESTAMP AS _created_at\n",
    "                FROM booster_output\n",
    "                \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "                SELECT\n",
    "                  {score_string} AS score,\n",
    "                  '{self.model_name}' AS model_name,\n",
    "                  CURRENT_TIMESTAMP AS _created_at\n",
    "                FROM booster_output\n",
    "                \"\"\"\n",
    "\n",
    "        return query\n",
    "\n",
    "    def _extract_clean_json(self, obj):\n",
    "        \"\"\"\n",
    "        This must always be applied to individual estimators within the json, not the full json.\n",
    "        \"\"\"\n",
    "\n",
    "        key_dict = {}\n",
    "        info_dict = {}\n",
    "\n",
    "        def _extract(obj, prev=None):\n",
    "\n",
    "            if isinstance(obj, dict):\n",
    "                if \"leaf\" in obj:\n",
    "                    key_dict.update({obj[\"nodeid\"]: obj[\"leaf\"]})\n",
    "                    info_dict.update({obj[\"nodeid\"]: {\"parent\": prev}})\n",
    "                elif \"split_condition\" not in obj:\n",
    "                    info_dict.update(\n",
    "                        {\n",
    "                            obj[\"nodeid\"]: {\n",
    "                                \"parent\": prev,\n",
    "                                \"split_column\": obj[\"split\"],\n",
    "                                \"split_number\": 1,\n",
    "                                \"if_equal_to\": obj[\"yes\"],\n",
    "                                \"if_not_equal_to\": obj[\"no\"],\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    info_dict.update(\n",
    "                        {\n",
    "                            obj[\"nodeid\"]: {\n",
    "                                \"parent\": prev,\n",
    "                                \"split_column\": obj[\"split\"],\n",
    "                                \"split_number\": obj[\"split_condition\"],\n",
    "                                \"if_less_than\": obj[\"yes\"],\n",
    "                                \"if_greater_than\": obj[\"no\"],\n",
    "                                \"if_null\": obj[\"missing\"],\n",
    "                            }\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                prev = obj[\"nodeid\"]\n",
    "\n",
    "                for k, v in obj.items():\n",
    "                    if isinstance(v, list):\n",
    "                        _extract(v, prev)\n",
    "\n",
    "            elif isinstance(obj, list):\n",
    "                for item in obj:\n",
    "                    _extract(item, prev)\n",
    "\n",
    "            return key_dict\n",
    "\n",
    "        results = _extract(obj)\n",
    "        return results, info_dict\n",
    "\n",
    "    @clean_multiline_str(prefix_nls=1, spaces=18)\n",
    "    def _recurse_case_whens(self,\n",
    "                            leaf_id: str,\n",
    "                            leaf_value: float,\n",
    "                            splits\n",
    "                            ) -> str:\n",
    "\n",
    "        query_list: List[str] = []\n",
    "\n",
    "        def _recurse(x) -> None:\n",
    "            prev_node_id = x\n",
    "            next_node_id = splits[prev_node_id][\"parent\"]\n",
    "\n",
    "            if next_node_id is not None:\n",
    "                next_node = splits[next_node_id]\n",
    "                if \"if_less_than\" in next_node:\n",
    "                    if (next_node[\"if_less_than\"] == prev_node_id) & (\n",
    "                        next_node[\"if_less_than\"] == next_node[\"if_null\"]\n",
    "                    ):\n",
    "                        text = f\"(({next_node['split_column']} < {next_node['split_number']}) OR ({next_node['split_column']} IS NULL))\"  # noqa: E501\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "                    elif next_node[\"if_less_than\"] == prev_node_id:\n",
    "                        text = f\"({next_node['split_column']} < {next_node['split_number']})\"\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "                    elif (next_node[\"if_greater_than\"] == prev_node_id) & (\n",
    "                        next_node[\"if_greater_than\"] == next_node[\"if_null\"]\n",
    "                    ):\n",
    "                        text = f\"(({next_node['split_column']} >= {next_node['split_number']}) OR ({next_node['split_column']} IS NULL))\"  # noqa: E501\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "                    elif next_node[\"if_greater_than\"] == prev_node_id:\n",
    "                        text = f\"({next_node['split_column']} >= {next_node['split_number']})\"\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "                elif \"if_equal_to\" in next_node:\n",
    "                    if next_node[\"if_equal_to\"] == prev_node_id:\n",
    "                        text = f\"({next_node['split_column']} = {next_node['split_number']})\"\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "                    elif next_node[\"if_not_equal_to\"] == prev_node_id:\n",
    "                        text = f\"({next_node['split_column']} <> {next_node['split_number']})\"\n",
    "                        query_list.insert(0, text)\n",
    "                        _recurse(next_node_id)\n",
    "\n",
    "        _recurse(leaf_id)\n",
    "\n",
    "        if query_list:\n",
    "            out_str = \"WHEN \" + \\\n",
    "                \" AND \".join(query_list) + f\" THEN {leaf_value}\"\n",
    "        else:\n",
    "            out_str = \"WHEN \" + \"TRUE\" + f\" THEN {leaf_value}\"\n",
    "        return out_str\n",
    "\n",
    "    def run(self) -> None:\n",
    "        # Get xgb in json format\n",
    "        tree_json = self._json_parse()\n",
    "        leaf_list = []\n",
    "        columns = []\n",
    "\n",
    "        # For each estimator\n",
    "        for i in range(len(tree_json)):\n",
    "\n",
    "            # Recurse to clean json and generate CASE WHENs\n",
    "            leaves, splits = self._extract_clean_json(tree_json[i])\n",
    "            estimator_list = []\n",
    "            for leaf_id, leaf_value in leaves.items():\n",
    "                estimator_list.append(\n",
    "                    self._recurse_case_whens(leaf_id, leaf_value, splits)\n",
    "                )\n",
    "            column = f\"column_{i}\"\n",
    "            columns.append(column)\n",
    "\n",
    "            # Generate the full CASE WHEN\n",
    "            estimator = f\"\"\"\n",
    "                CASE {''.join(estimator_list)}\n",
    "                END AS {column}\"\"\"\n",
    "            estimator = clean_multiline_str(prefix_nls=0, suffix_nls=0, spaces=16)(\n",
    "                lambda: estimator\n",
    "            )()\n",
    "            leaf_list.append(estimator)\n",
    "\n",
    "        # Combine all estimators\n",
    "        query_top = f\"\"\"\n",
    "            WITH booster_output AS (\n",
    "              SELECT\n",
    "                {', '.join(self.index_columns + leaf_list)}\n",
    "              FROM {self.data_source_name}\n",
    "            )\n",
    "            \"\"\"\n",
    "        query_top = clean_multiline_str(prefix_nls=0, suffix_nls=0, spaces=0)(\n",
    "            lambda: query_top\n",
    "        )()\n",
    "\n",
    "        # Create the last SELECT clause\n",
    "        query_bottom = self._sql_eval(columns)\n",
    "\n",
    "        # Final query\n",
    "        query = f\"{query_top}{query_bottom}\"\n",
    "\n",
    "        with open(self.OUTPUT_PATH, \"w\") as f:\n",
    "            f.write(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgb2sql import XGBFmap, XGB2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=5, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = xgb.XGBClassifier(n_estimators=5)\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbFmap = XGBFmap()\n",
    "xgbFmap.create_fmap(X)\n",
    "tree = XGB2SQL(xgb_model=m, model_type='Classifier',data_source_name='breast_cancer')\n",
    "xgbFmap.delete_fmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH booster_output AS (\n",
      "\tSELECT\n",
      "\t\tCASE\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND ((f10 < 0.591250002) OR (f10 IS NULL))\n",
      "\t\tTHEN 0.191869915\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND (f10 >= 0.591250002)\n",
      "\t\tTHEN 0\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND ((f1 < 18.9599991) OR (f1 IS NULL))\n",
      "\t\tTHEN 0.120000005\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND (f1 >= 18.9599991)\n",
      "\t\tTHEN -0.13333334\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND ((f23 < 785.799988) OR (f23 IS NULL))\n",
      "\t\t\tAND ((f21 < 23.7399998) OR (f21 IS NULL))\n",
      "\t\tTHEN 0.155555561\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND ((f23 < 785.799988) OR (f23 IS NULL))\n",
      "\t\t\tAND (f21 >= 23.7399998)\n",
      "\t\tTHEN -0.100000001\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND (f23 >= 785.799988)\n",
      "\t\t\tAND ((f1 < 14.3000002) OR (f1 IS NULL))\n",
      "\t\tTHEN 0\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND (f23 >= 785.799988)\n",
      "\t\t\tAND (f1 >= 14.3000002)\n",
      "\t\tTHEN -0.191176474\n",
      "\t\tEND AS column_0, \n",
      "\t\tCASE\n",
      "\t\t\tWHEN ((f7 < 0.0500999987) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND ((f13 < 38.6049995) OR (f13 IS NULL))\n",
      "\t\tTHEN 0.17467472\n",
      "\t\t\tWHEN ((f7 < 0.0500999987) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND (f13 >= 38.6049995)\n",
      "\t\tTHEN 0.0302315652\n",
      "\t\t\tWHEN ((f7 < 0.0500999987) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND ((f1 < 18.9599991) OR (f1 IS NULL))\n",
      "\t\tTHEN 0.113052242\n",
      "\t\t\tWHEN ((f7 < 0.0500999987) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND (f1 >= 18.9599991)\n",
      "\t\tTHEN -0.124826349\n",
      "\t\t\tWHEN (f7 >= 0.0500999987)\n",
      "\t\t\tAND ((f22 < 103.25) OR (f22 IS NULL))\n",
      "\t\t\tAND ((f21 < 25.9249992) OR (f21 IS NULL))\n",
      "\t\tTHEN 0.140555695\n",
      "\t\t\tWHEN (f7 >= 0.0500999987)\n",
      "\t\t\tAND ((f22 < 103.25) OR (f22 IS NULL))\n",
      "\t\t\tAND (f21 >= 25.9249992)\n",
      "\t\tTHEN -0.0846852511\n",
      "\t\t\tWHEN (f7 >= 0.0500999987)\n",
      "\t\t\tAND (f22 >= 103.25)\n",
      "\t\t\tAND ((f21 < 20.3549995) OR (f21 IS NULL))\n",
      "\t\tTHEN -0.01987583\n",
      "\t\t\tWHEN (f7 >= 0.0500999987)\n",
      "\t\t\tAND (f22 >= 103.25)\n",
      "\t\t\tAND (f21 >= 20.3549995)\n",
      "\t\tTHEN -0.174933031\n",
      "\t\tEND AS column_1, \n",
      "\t\tCASE\n",
      "\t\t\tWHEN ((f27 < 0.142349988) OR (f27 IS NULL))\n",
      "\t\t\tAND ((f20 < 17.6149998) OR (f20 IS NULL))\n",
      "\t\t\tAND ((f13 < 35.2600021) OR (f13 IS NULL))\n",
      "\t\tTHEN 0.159918889\n",
      "\t\t\tWHEN ((f27 < 0.142349988) OR (f27 IS NULL))\n",
      "\t\t\tAND ((f20 < 17.6149998) OR (f20 IS NULL))\n",
      "\t\t\tAND (f13 >= 35.2600021)\n",
      "\t\tTHEN 0.0472318567\n",
      "\t\t\tWHEN ((f27 < 0.142349988) OR (f27 IS NULL))\n",
      "\t\t\tAND (f20 >= 17.6149998)\n",
      "\t\t\tAND ((f29 < 0.0649200007) OR (f29 IS NULL))\n",
      "\t\tTHEN -0.0155247366\n",
      "\t\t\tWHEN ((f27 < 0.142349988) OR (f27 IS NULL))\n",
      "\t\t\tAND (f20 >= 17.6149998)\n",
      "\t\t\tAND (f29 >= 0.0649200007)\n",
      "\t\tTHEN -0.119407289\n",
      "\t\t\tWHEN (f27 >= 0.142349988)\n",
      "\t\t\tAND ((f23 < 729.549988) OR (f23 IS NULL))\n",
      "\t\t\tAND ((f4 < 0.1083) OR (f4 IS NULL))\n",
      "\t\tTHEN 0.120342232\n",
      "\t\t\tWHEN (f27 >= 0.142349988)\n",
      "\t\t\tAND ((f23 < 729.549988) OR (f23 IS NULL))\n",
      "\t\t\tAND (f4 >= 0.1083)\n",
      "\t\tTHEN -0.108723581\n",
      "\t\t\tWHEN (f27 >= 0.142349988)\n",
      "\t\t\tAND (f23 >= 729.549988)\n",
      "\t\t\tAND ((f10 < 0.241250008) OR (f10 IS NULL))\n",
      "\t\tTHEN -0.0287595335\n",
      "\t\t\tWHEN (f27 >= 0.142349988)\n",
      "\t\t\tAND (f23 >= 729.549988)\n",
      "\t\t\tAND (f10 >= 0.241250008)\n",
      "\t\tTHEN -0.163232192\n",
      "\t\tEND AS column_2, \n",
      "\t\tCASE\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND ((f10 < 0.528550029) OR (f10 IS NULL))\n",
      "\t\tTHEN 0.151598975\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND ((f20 < 16.8250008) OR (f20 IS NULL))\n",
      "\t\t\tAND (f10 >= 0.528550029)\n",
      "\t\tTHEN 0.0131686451\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND ((f1 < 18.9599991) OR (f1 IS NULL))\n",
      "\t\tTHEN 0.101920418\n",
      "\t\t\tWHEN ((f7 < 0.0489199981) OR (f7 IS NULL))\n",
      "\t\t\tAND (f20 >= 16.8250008)\n",
      "\t\t\tAND (f1 >= 18.9599991)\n",
      "\t\tTHEN -0.113945559\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND ((f23 < 785.799988) OR (f23 IS NULL))\n",
      "\t\t\tAND ((f21 < 23.7399998) OR (f21 IS NULL))\n",
      "\t\tTHEN 0.131930456\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND ((f23 < 785.799988) OR (f23 IS NULL))\n",
      "\t\t\tAND (f21 >= 23.7399998)\n",
      "\t\tTHEN -0.0824727714\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND (f23 >= 785.799988)\n",
      "\t\t\tAND ((f12 < 2.02349997) OR (f12 IS NULL))\n",
      "\t\tTHEN -0.0275684185\n",
      "\t\t\tWHEN (f7 >= 0.0489199981)\n",
      "\t\t\tAND (f23 >= 785.799988)\n",
      "\t\t\tAND (f12 >= 2.02349997)\n",
      "\t\tTHEN -0.155280709\n",
      "\t\tEND AS column_3, \n",
      "\t\tCASE\n",
      "\t\t\tWHEN ((f27 < 0.145449996) OR (f27 IS NULL))\n",
      "\t\t\tAND ((f22 < 107.599998) OR (f22 IS NULL))\n",
      "\t\t\tAND ((f13 < 46.7900009) OR (f13 IS NULL))\n",
      "\t\tTHEN 0.142997682\n",
      "\t\t\tWHEN ((f27 < 0.145449996) OR (f27 IS NULL))\n",
      "\t\t\tAND ((f22 < 107.599998) OR (f22 IS NULL))\n",
      "\t\t\tAND (f13 >= 46.7900009)\n",
      "\t\tTHEN 0.00895034242\n",
      "\t\t\tWHEN ((f27 < 0.145449996) OR (f27 IS NULL))\n",
      "\t\t\tAND (f22 >= 107.599998)\n",
      "\t\t\tAND ((f21 < 20.0849991) OR (f21 IS NULL))\n",
      "\t\tTHEN 0.12236432\n",
      "\t\t\tWHEN ((f27 < 0.145449996) OR (f27 IS NULL))\n",
      "\t\t\tAND (f22 >= 107.599998)\n",
      "\t\t\tAND (f21 >= 20.0849991)\n",
      "\t\tTHEN -0.0948726162\n",
      "\t\t\tWHEN (f27 >= 0.145449996)\n",
      "\t\t\tAND ((f23 < 710.200012) OR (f23 IS NULL))\n",
      "\t\t\tAND ((f21 < 25.0550003) OR (f21 IS NULL))\n",
      "\t\tTHEN 0.0869635344\n",
      "\t\t\tWHEN (f27 >= 0.145449996)\n",
      "\t\t\tAND ((f23 < 710.200012) OR (f23 IS NULL))\n",
      "\t\t\tAND (f21 >= 25.0550003)\n",
      "\t\tTHEN -0.0576682575\n",
      "\t\t\tWHEN (f27 >= 0.145449996)\n",
      "\t\t\tAND (f23 >= 710.200012)\n",
      "\t\t\tAND ((f6 < 0.0892650038) OR (f6 IS NULL))\n",
      "\t\tTHEN -0.0451009385\n",
      "\t\t\tWHEN (f27 >= 0.145449996)\n",
      "\t\t\tAND (f23 >= 710.200012)\n",
      "\t\t\tAND (f6 >= 0.0892650038)\n",
      "\t\tTHEN -0.147640571\n",
      "\t\tEND AS column_4\n",
      "\tFROM breast_cancer\n",
      "\tWHERE source = 'test'\n",
      ")\n",
      "\n",
      "SELECT \n",
      "    1 / ( 1 + EXP ( - ( \n",
      "    column_0\n",
      "\t+ column_1\n",
      "\t+ column_2\n",
      "\t+ column_3\n",
      "\t+ column_4 ) ) ) AS score\n",
      "FROM booster_output\n"
     ]
    }
   ],
   "source": [
    "print(tree.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}